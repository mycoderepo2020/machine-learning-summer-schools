{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Totorial_on_TDL.ipynb","version":"0.3.2","provenance":[{"file_id":"1yxLQ__c3CXWHlncdggTHmx0lSq5TL1eG","timestamp":1567109777001}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wvp6pvjo6UoG","colab_type":"text"},"source":["# Deep Learning Theory: Tutorial\n","The tutorial consists of two sections. Section 1 is related to **approximation** properties of the ReLU networks, whereas Section 2 is about **expressiveness** of fully connected networks. We will use ``pytorch`` (section 1) and ``numpy`` (section 2)."]},{"cell_type":"code","metadata":{"id":"AxiiTwvBqnkw","colab_type":"code","colab":{}},"source":["import torch\n","from torch import nn\n","\n","%matplotlib inline\n","import matplotlib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import requests\n","import IPython.display as Disp\n","\n","from IPython.display import clear_output\n","\n","from tqdm import tqdm_notebook as tqdm\n","\n","DEVICE = 'cpu'\n","if torch.cuda.is_available():\n","    DEVICE = 'cuda'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fikT6GEJtJrS","colab_type":"text"},"source":["# Section 1. Approximation battle: Practice vs. Theory\n","\n","One of the most important problems of the **Deep Learning**, is for a given task to find the **appropriate** neural network architecture. Typically, the word **appropriate** means that the neural network with the given architecture\n","* Can **efficienty approximate the target function**: not overparametrized (\"not many\" parameters);\n","* Is **easy to fit**: has good local minima, optimization converges fast, does not overfit, etc;\n","\n","For many existing **benchmark** problems (Classification on MNIST, Faces Generation on CelebA, etc.) there exist only receipes which architecture to use (e.g. AlexNets, UNets, ResNets,...), which activations to apply, which heuristics to implement (batchnorms, additional noise, regularization, etc.). All these **recipes** are mainly **based on practical experience** of thousands of researchers.\n","\n","During this part of the tutorial, we will see that even for the toy artificial problem it is nearly impossible to **practically** develop an efficient ReLU neural network that approximate the desired function well.\n","\n","## Our goal\n","\n","The goal is to **solve** the following **approximation problem**:\n","\n","--------------------------------------------------------------------------------\n","\n","Design a ReLU network with fewer than 10000 connections that approximates the function $f(x)=\\sin x$ on the segment $[-\\pi, \\pi]$ with uniform error not greater than $10^{-12}$. Implement the network in a Python notebook. Count the number of connections and demonstrate that the error bound is satisfied.\n","\n","--------------------------------------------------------------------------------\n","\n","This task is not as easy as it might seem.\n","\n","## Part 1. Practical Perspectives\n","We begin with the most straightforward approach: simply to **fit** such a **network from scratch**. We are going to use ``pytorch`` in this section. Make sure that your model you uses ``double`` data type (``float64``). The usage of ``float32`` (default) is not enough to solve the problem.\n","\n","In the code below please set up the **network architecture** that is, in your opinion, the most suitable for this problem. It may not be necessarily Sequential, may contain **batchnorms** and **droupouts** or any other heuristic you like. The only restriction is that **all the nonlinearities must be ReLUs**."]},{"cell_type":"code","metadata":{"id":"O8y24J5btNHF","colab_type":"code","colab":{}},"source":["net = nn.Sequential(\n","    # Paste your network instead of this one\n","    nn.Linear(1, 50),\n","    nn.ReLU(),\n","    nn.Dropout(0.03),\n","    nn.Linear(50, 50),\n","    nn.ReLU(),\n","    nn.Linear(50, 50),\n","    nn.BatchNorm1d(50),\n","    nn.ReLU(),\n","    nn.Linear(50, 25),\n","    nn.Dropout(0.03),\n","    nn.ReLU(),\n","    nn.Linear(25, 25),\n","    nn.ReLU(),\n","    nn.Linear(25, 1),\n",").to(DEVICE).double()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IneJBWepyhHP","colab_type":"text"},"source":["Althought the number of **connections** does not necessary equal the number of **parameters** (it is greater), for simplicity we equalise these concepts.\n","\n","Check that your network does not have **too many parameters** (>10000) by launching the code below. \n"]},{"cell_type":"code","metadata":{"id":"lxKivblOyDeo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"92706622-162e-4da4-f8df-f32ee3d65b1c","executionInfo":{"status":"ok","timestamp":1567424156034,"user_tz":-180,"elapsed":1523,"user":{"displayName":"Alex Korotin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAr1kW5srwn5hvvZW_45J2JqUNECW6CQ9A3BppdOg=s64","userId":"13587422623728399626"}}},"source":["num_parameters = np.sum([np.prod(par.data.shape) for par in net.parameters()])\n","if num_parameters > 10000:\n","  print('Your network has too many parameters! Change it!')\n","else:\n","  print('Your network is ok. Move forward!')\n","print('Number of parameters: {}'.format(num_parameters))"],"execution_count":67,"outputs":[{"output_type":"stream","text":["Your network is ok. Move forward!\n","Number of parameters: 7251\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2gAG2ZZ_52Oy","colab_type":"text"},"source":["Set the main **training  details**, such as optimizer from ``torch.optim``, number of iterations, batch generation procedure, etc."]},{"cell_type":"code","metadata":{"id":"kUV3fMvWtbtG","colab_type":"code","colab":{}},"source":["def create_batch(batch_size=1024 * 16):\n","  return torch.rand(batch_size, 1, device=DEVICE, dtype=torch.double) * 2 * np.pi - np.pi\n","\n","opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n","max_iterations = 2 ** 14\n","loss_history = []"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c1t5quzf61fw","colab_type":"text"},"source":["Define the loss function. Although we need to optimize **max absolute error**, it is typically reasonable to use **mean absolute error** or (root of) **mean squared error**."]},{"cell_type":"code","metadata":{"id":"f0quC25I7PlN","colab_type":"code","colab":{}},"source":["def get_loss(y_true, y_pred):\n","  return (y_true - y_pred).abs().max()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HHhrY27O54k_","colab_type":"text"},"source":["Train your network. Feel free to do anything "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RAPqjSrR46Uz","colab":{"base_uri":"https://localhost:8080/","height":512},"outputId":"05263b0f-f83b-4b1d-9170-59547d77941b","executionInfo":{"status":"error","timestamp":1567424202945,"user_tz":-180,"elapsed":2460,"user":{"displayName":"Alex Korotin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAr1kW5srwn5hvvZW_45J2JqUNECW6CQ9A3BppdOg=s64","userId":"13587422623728399626"}}},"source":["plot_loss_every = 256\n","net.train(True)\n","\n","for iteration in tqdm(range(max_iterations)):\n","    X = create_batch()\n","    \n","    loss = get_loss(torch.sin(X), net(X))\n","    loss.backward()\n","    opt.step()\n","    opt.zero_grad()\n","    \n","    loss_history.append(loss.item())\n","    if iteration % plot_loss_every == 0:\n","        clear_output(wait=True)\n","        plt.plot(np.log10(loss_history))\n","        plt.title('Log10 of loss')\n","        plt.show()"],"execution_count":72,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDxHxFwRBqIeI+AuCINRDRPwFQRDqIf8PDSz11QDRu14AAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-72-3c02b0c799c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mplot_loss_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"kBPy9ZuLznyO","colab_type":"text"},"source":["**Score** your network on segment $[-\\pi, \\pi]$ to see whether the desired accuracy achieved."]},{"cell_type":"code","metadata":{"id":"-w2536UWt3Ru","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":274},"outputId":"ddd0f3ea-285f-4646-c1fe-c0f36cb801ea","executionInfo":{"status":"ok","timestamp":1567424213360,"user_tz":-180,"elapsed":1750,"user":{"displayName":"Alex Korotin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAr1kW5srwn5hvvZW_45J2JqUNECW6CQ9A3BppdOg=s64","userId":"13587422623728399626"}}},"source":["X = torch.linspace(-np.pi, np.pi, 1000000, dtype=torch.double).reshape(-1, 1).to(DEVICE)\n","\n","net.train(False)\n","max_error = (net(X) - torch.sin(X)).abs().max().item()\n","\n","if max_error <= 1e-12:\n","    print('I do not believe you did it!')\n","    url = 'https://i.ibb.co/Msqh8GR/what-did-you-say.png'\n","else:\n","    print('You failed :(')\n","    url = 'https://i.ibb.co/J2RzYtB/no-no.jpg'\n","print('log10 of loss: {}'.format(np.log10(max_error)))\n","\n","Disp.Image(requests.get(url).content, width=220, height=220)"],"execution_count":73,"outputs":[{"output_type":"stream","text":["You failed :(\n","log10 of loss: -0.7394955499165674\n"],"name":"stdout"},{"output_type":"execute_result","data":{"image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxISEhUTExMWFRUVFRUYFxcYFRUXFhkSFxYWFxgX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\npSgUpSgUpSgUpSgUpSgUpSgUpSgUpSg//9k=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[],"image/jpeg":{"width":220,"height":220}},"execution_count":73}]},{"cell_type":"markdown","metadata":{"id":"TSCCcEIuFA7N","colab_type":"text"},"source":["## Part 2. Theoretical Perspectives\n","Suprisingly, but the approximation of $sin(x)$ can be reduced simply to approximation of $sqr(x)=x^{2}$. Let us see why!\n","\n","### Part 2.1. From general to specific\n"," \n","#### (1) General Approximation Scheme\n","Recall that analytic functions can be (locally!) constructed by using only two bivariate functions, sum \"$+$\" and product \"$\\cdot$\". The **Taylor series** of analytic function is:\n","$$f(x_{1},x_{2},\\dots, x_{n})=f(x_{1}^{0},\\dots, x_{n}^{0})+\\sum_{i=1}^{n}\\frac{\\partial f}{\\partial x_{i}}\\cdot (x_{i}-x_{i}^{0})+\\frac{1}{2!}\\sum_{i, j}\\frac{\\partial^{2}f}{x_{i}x_{j}}\\cdot (x_{i}-x_{i}^{0})\\cdot (x_{j}-x_{j}^{0})+\\dots$$\n","By taking several first turms we obtain (hopefully good) approximation. Every term in the approximation is a **monomial**. Thus, to build an efficient approximation of the function $f$ we can \n","* approximate $f$ by several first terms of its Taylor Series\n","* efficiently approximate the terms (monomials) in series by a neural networks\n","* sum the approximations for terms\n","\n","#### (2) Sine Function Approximation\n","\n","In case of $sin(x)$ function we have:\n","$$sin(x)=x-\\frac{x^{3}}{3!}+\\frac{x^{5}}{5!}-\\frac{x^{7}}{7!}+\\dots.$$\n","Thus, our **goal** is to **efficiently** approximate monomials $x^{n}$ by the ReLU neural network.\n","\n","#### (3) Product function approximation\n","\n","Monomial can be obtained from $x$ by product function, e.g. $x^{n}=prod(x, x^{n-1})$. Thus, we need to efficiently approximate bivariate function\n","$$prod(x,y)=xy$$\n","by a ReLU neural network!\n","\n","#### (4) Square function approximation\n","Let us start from approximation of $prod(x,x)=sqr(x)=x^2$ for $x\\in[0, 1]$. **That is ENOUGH. But why?** Since \n","$$prod(x, y)=xy=\\big[\\frac{(x+y)}{2}\\big]^{2}-\\big[\\frac{(x-y)}{2}\\big]^{2},$$\n","we can use square approximation for product approximation!\n","\n","$$\\tilde{prod}(x, y)=\\tilde{sqr}\\big(\\frac{(x+y)}{2}\\big)-\\tilde{sqr}\\big(\\frac{(x-y)}{2}\\big).$$\n","\n","## Part 2.2 Square and product approximation\n","\n","Efficient ReLU approximation for $x\\mapsto x^{2}$ was proposed by D.Yarotskiy, [arXiv:1610.01145](https://arxiv.org/pdf/1610.01145.pdf). It uses the \"**tooth**\" function.\n","\n","#### (1) Tooth function\n","The function is given by\n","$$g(x)=\\begin{cases}\n","               2x, & x<0.5\\\\\n","               2(1-x), & x\\geq 0.5\n","            \\end{cases}$$"]},{"cell_type":"code","metadata":{"id":"zJPa0kh8WslV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":287},"outputId":"2db1e01a-ecee-4542-cf43-4a6fbb799fb7","executionInfo":{"status":"ok","timestamp":1567424443280,"user_tz":-180,"elapsed":929,"user":{"displayName":"Alex Korotin","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAr1kW5srwn5hvvZW_45J2JqUNECW6CQ9A3BppdOg=s64","userId":"13587422623728399626"}}},"source":["def tooth(x):\n","  assert x.max().item() <= 1\n","  assert x.min().item() >= 0\n","  return (x < 0.5).double() * 2 * x + (x >= 0.5).double() * 2 * (1-x)\n","\n","X = torch.linspace(0., 1., 1000, device=DEVICE, dtype=torch.double)\n","plt.plot(X.cpu().numpy(), tooth(X).cpu().detach().numpy(), label='tooth'); plt.legend()"],"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7fba335f5da0>"]},"metadata":{"tags":[]},"execution_count":74},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"uLzbqqnRWrOY","colab_type":"text"},"source":["This function is pieswise-linear, thus it can be represented as a weighted sum of ReLU functions (neurons). Please, define it below  the by using Rectifier Linear Units (ReLUs)."]},{"cell_type":"code","metadata":{"id":"ESLBc9fGFF-q","colab_type":"code","colab":{}},"source":["def tooth(x):\n","  assert x.max().item() <= 1\n","  assert x.min().item() >= 0\n","  return # YOUR SOLUTION HERE SOLUTION\n","\n","plt.plot(X.cpu().numpy(), tooth(X).cpu().detach().numpy(), label='tooth?'); plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cfzQWgEbX_HU","colab_type":"text"},"source":["#### (2) Sawtooth function\n","A powerful feature of the tooth function, is that iterated calling it produces **sawtooth** constructions. We denote \n","$$g_{s}(x)=\\overbrace{g(g(g(\\dots g}^{s\\text{ times}}(x)))).$$\n","Let us look at the plot!"]},{"cell_type":"code","metadata":{"id":"CB5G30vpYEKW","colab_type":"code","colab":{}},"source":["plt.plot(X.cpu().numpy(), tooth(X).cpu().detach().numpy(), label='tooth(tooth(x))');\n","plt.plot(X.cpu().numpy(), tooth(tooth(X)).cpu().detach().numpy(), label='tooth(tooth(x))');\n","plt.plot(X.cpu().numpy(), tooth(tooth(tooth(X))).cpu().detach().numpy(), label='tooth(tooth(tooth(x)))');\\\n","plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GxGHx6KqyOXY","colab_type":"text"},"source":["#### (3) Sawtooth approximation of $sqr(x)$\n","With the help of the following theorem, we are going to implement an efficient approximation of $sqr(x)=x^{2}$ on $[-1, 1]$.\n","#### Theorem (D. Yarotsky, 2016)\n","The following function\n","$$f_{n}(x)=x-\\sum_{s=1}^{n}\\frac{g_{s}(x)}{2^{2s}}$$\n","uniformly approximates $x^{2}$ on $[0, 1]$ with error $<2^{-2n-2}$ and can be represented by a ReLU network with $O(n)$ connections:\n","\n","<br><center><img src=\"https://i.ibb.co/2hnNXSc/sqr-approx-net.png\" alt=\"sqr-approx-net\" border=\"0\"></center></br>\n","\n","It is easy to add additional layer $|x|=ReLU(x)+ReLU(-x)$ to make the function approximate $x^{2}$ on $[-1, 1]$ instead of $[0, 1]$.\n","\n","<br><center><img src=\"https://i.ibb.co/k0Nw3Xf/sqr-approx-net-full.png\" alt=\"sqr-approx-net-full\" border=\"0\"></center></br>\n","\n","From the image it is easy to see that for $n$ blocks the **number of connections** is $5n+5$.\n","\n","Implement the  described network."]},{"cell_type":"code","metadata":{"id":"ungra0BTYREl","colab_type":"code","colab":{}},"source":["def sqr(x, n_layers=25):\n","    assert torch.abs(x).max().item() <= 1.\n","    x = torch.relu(x) + torch.relu(-x)\n","    \n","    ans = 1. * x\n","    sawtooth = 1. * x\n","    for n in range(n_layers):\n","        sawtooth = # YOUR SOLUTION HERE\n","        ans -= # YOUR SOLUTION HERE\n","    return ans"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"waKEQEp56LUv","colab_type":"text"},"source":["Check the function visually."]},{"cell_type":"code","metadata":{"id":"PEDYLtoa5hjs","colab_type":"code","colab":{}},"source":["X = torch.linspace(-1, 1, 10000, device=DEVICE, dtype=torch.double)\n","plt.plot(X.cpu().numpy(), sqr(X, 1).cpu().detach().numpy(), label='1 iter')\n","plt.plot(X.cpu().numpy(), sqr(X, 2).cpu().detach().numpy(), label='2 iters')\n","plt.plot(X.cpu().numpy(), (X**2).cpu().detach().numpy(), label='True')\n","plt.legend(); plt.xlabel('x'); plt.ylabel('f(x)');"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q0YV2mQT6O4O","colab_type":"text"},"source":["Check the improvement of approximation numerically. Run the cell below."]},{"cell_type":"code","metadata":{"id":"5b7z6aq35y9C","colab_type":"code","colab":{}},"source":["max_errors = []\n","for n_blocks in tqdm(range(0, 50)):\n","  error = torch.abs(X ** 2 - sqr(X, n_blocks)).max().item()\n","  max_errors.append(error)\n","    \n","plt.plot(np.log10(max_errors)); plt.xlabel('Number of blocks in approximation.')\n","plt.title('Log10 Max error on [-1, 1]'); plt.ylabel('log10(Error)')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NG1xhwJg8qo9","colab_type":"text"},"source":["As you may note, after ~25 layers the accuracy does not improve. This happend due to **hardware precision limitation**. If you use float32 type (single precision) instead of float64 (double precision), the accuracy will stop improving even on ~12 layers (you may also check this!)."]},{"cell_type":"markdown","metadata":{"id":"94XzEbw1Atlk","colab_type":"text"},"source":["#### (3) Sawtooth approximation of product\n","Approximate the product function $prod(x, y)=xy$ on $[-1, 1]$ by using the approximation of square function.\n","$$\\tilde{prod}(x, y)=\\tilde{sqr}\\big(\\frac{(x+y)}{2}\\big)-\\tilde{sqr}\\big(\\frac{(x-y)}{2}\\big).$$"]},{"cell_type":"code","metadata":{"id":"OFuCPViO8rKz","colab_type":"code","colab":{}},"source":["def prod(x, y, n_layers=15):\n","    assert torch.abs(x).max().item() <= 1.\n","    assert torch.abs(y).max().item() <= 1.\n","    \n","    # YOUR SOLUTION HERE\n","    \n","    return # YOUR SOLUTION HERE"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fluxz1HcF--O","colab_type":"text"},"source":["If the inner $\\tilde{sqr}$ networks uses $n$ tooth blocks, the $\\tilde{prod}$ function will have $(5n+5) * 2 + 6 = 10n+16$ connections.\n","## Part 2.3. $Sin(x)$ efficient approximation\n","Note that our functions (approximations of) $sqr(x)$ and $prod(x,y)$ approximate the corresponding function only for $x, y\n","\\in[0,1]$. Thus, we have to monitor that all the inputs to function $sqr, prod$ lie within $[-1, 1]$. Let us denote $z=\\frac{x}{\\pi}$. Then\n","$$sin(x)=sin(2\\pi z)=\\sum_{n=0}^{\\infty}(-1)^{n}z^{2n+1}\\frac{(2\\pi)^{2n+1}}{(2n+1)!}.$$\n","Now we can efficiently compute all the powers of $z$, multiply them by coefficients $\\frac{(2\\pi)^{2n+1}}{(2n+1)!}<10$ (this will only decrease accuracy not worse than 10 times) and sum the obtained values.\n","\n","<br><center><img src=\"https://i.ibb.co/MZGTffQ/sin-approx-net-full.png\" alt=\"sin-approx-net\" border=\"0\" height=300></center></br>\n","\n","If $m$ first taylor series terms are used for approximation and each sqr block uses $n$ tooth blocks, the total number of connections in the network is:\n","$$\\text{total connctions}=1+\\underbrace{(5n+5)}_{\\text{sqr block}}+(m-1) * \\underbrace{(10n+16)}_{\\text{prod block}}+m$$\n","\n","For $m=20$ and $n=25$ the exact **number of connections is 5180**.\n","\n","Now your job is to **implement this network**.\n"]},{"cell_type":"code","metadata":{"id":"LxGPvakEDVlM","colab_type":"code","colab":{}},"source":["def sin(x, terms=20, sqr_layers=25):\n","    z = x / np.pi\n","    \n","    ans = z\n","    pow_z = z\n","    sqr_z = sqr(z, n_layers=sqr_layers)\n","    ratio = 1.\n","    for n in tqdm(range(1, terms)):\n","        # YOUR SOLUTION HERE\n","        \n","    ans *= np.pi\n","    \n","    return ans"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D2qivx7o43-H","colab_type":"text"},"source":["Check what you have done!"]},{"cell_type":"code","metadata":{"id":"yIQS6jy0Y1OO","colab_type":"code","colab":{}},"source":["X = torch.linspace(-np.pi+1e-12, np.pi-1e-12, 10000, device=DEVICE, dtype=torch.double)\n","sinX = sin(X)\n","\n","plt.plot(X.cpu().numpy(), sinX.cpu().detach().numpy())\n","\n","max_error = torch.abs(torch.sin(X) - sinX).max().item()\n","log10_error = np.log10(max_error)\n","\n","if log10_error < -12:\n","    print('Success! You are awesome!')\n","    url = \"https://i.ibb.co/DVqCb8K/perfect.png\"\n","else:\n","    print('Too huge error!')\n","    url = 'https://i.ibb.co/J2RzYtB/no-no.jpg'\n","    \n","print('log10 max error: {}'.format(round(np.log10(max_error), 2)))\n","Disp.Image(requests.get(url).content, width=220, height=220)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6T91Mbjk_7xz","colab_type":"text"},"source":["## Part 2.4. Can you fit such a monster?\n","Even when we know the good architecture, we are not able to fit it. Or can we?\n","Let us implement the Sqr Neural network but (in contrast to previous approach) with weights as choosable parameters."]},{"cell_type":"code","metadata":{"id":"q1p4FtYA-FXV","colab_type":"code","colab":{}},"source":["class SqrNet(nn.Module):\n","  def __init__(self, n_layers=25):\n","    super(SqrNet, self).__init__()\n","    self.tooth = nn.Sequential(\n","        nn.Linear(1, 2, bias=True),\n","        nn.ReLU(),\n","        nn.Linear(2, 1, bias=False)\n","    )\n","    \n","    self.n_layers = n_layers\n","    \n","    self.abs = nn.Sequential(\n","        nn.Linear(1, 2, bias=False),\n","        nn.ReLU(),\n","        nn.Linear(2, 1, bias=False)\n","    )\n","    \n","    self.main = nn.Linear(n_layers+1, 1)\n","    \n","  def forward(self, x):\n","    x = self.abs(x)\n","    layers = [x]\n","    for _ in range(self.n_layers):\n","      layers.append(self.tooth(layers[-1]))\n","    layers = torch.cat(layers, dim=1)\n","    return self.main(layers)\n","\n","torch.manual_seed(0xBADBAAD)\n","sqr_net = SqrNet(n_layers=4).to(DEVICE).double()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m-PrK_moAh7L","colab_type":"text"},"source":["Now we try to fit such the problem-specific neural network to represent the function $sqr(x)=x^{2}$. Can we achieve accuracy $10^{-12}$?"]},{"cell_type":"code","metadata":{"id":"BDB3YdWNAdvB","colab_type":"code","colab":{}},"source":["def get_loss(y_true, y_pred):\n","  return (y_true - y_pred).abs().mean()\n","\n","opt = torch.optim.Adam(sqr_net.parameters(), lr=1e-3, weight_decay=1e-3)\n","max_iterations = 2 ** 12\n","loss_history = []\n","\n","plot_loss_every = 128\n","sqr_net.train(True)\n","\n","for iteration in tqdm(range(max_iterations)):\n","    X = torch.rand(10000, 1, device=DEVICE, dtype=torch.float64) * 2 - 1\n","    \n","    loss = get_loss(X ** 2, sqr_net(X))\n","    loss.backward()\n","    opt.step()\n","    opt.zero_grad()\n","    \n","    loss_history.append(loss.item())\n","    if iteration % plot_loss_every == 0:\n","        clear_output(wait=True)\n","        fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n","        axes[0].plot(np.log10(loss_history))\n","        axes[0].set_title('Log10 of loss')\n","        \n","        X = torch.linspace(-10, 10, 1000, device=DEVICE, dtype=torch.double).reshape(-1, 1)\n","        axes[1].plot(X.cpu().numpy(), sqr_net(X).cpu().detach().numpy(), label='Sqr Net')\n","        axes[1].plot(X.cpu().numpy(), (X**2).cpu().detach().numpy(), label='True')\n","        axes[1].legend(); axes[1].set_xlabel('x'); axes[1].set_ylabel('f(x)');\n","        \n","        axes[2].plot(X.cpu().numpy(), sqr_net.abs(X).cpu().detach().numpy(), label='Fitted Abs Function')\n","        axes[2].legend(); axes[2].set_xlabel('x'); axes[2].set_ylabel('abs(x)');\n","                \n","        X = torch.linspace(-10, 10, 1000, device=DEVICE, dtype=torch.double).reshape(-1, 1)\n","        axes[3].plot(X.cpu().numpy(), sqr_net.tooth(X).cpu().detach().numpy(), label='Fitted Tooth Function')\n","        axes[3].legend(); axes[3].set_xlabel('x'); axes[3].set_ylabel('tooth(x)');\n","        \n","        plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ak5iWoRM7p0R","colab_type":"text"},"source":["## Part 3. Homework\n","* Prove theoretically that the obtained network attains the desired maximal absolute error $<10^{-12}$. You may want to use the theorem from above.\n","\n","# Section 2. Expressiveness analysis via propagation in random neural networks\n","\n","In this part of the tutorial we will try to understand some expressiveness-related properties of the neural networks. We will study how the signal propagates through the neural network. Here for simplicity we will use ``numpy`` instead of ``pytorch``.\n","\n","Consider the fully connected neural network with layer width $d_{0},d_{1},\\dots d_{n}\\rightarrow \\infty$:\n","$$x_{n}=h\\bigg(W_{n}\\cdot h\\big(W_{n-1}\\cdot h(\\dots)+b_{n-1}\\big)+b_{n}\\bigg)$$\n","with the following sequential decomposition:\n","$$x_{1}=\\sigma(W_{1}\\cdot x_{0}+b_{1});\\qquad x_{2}=\\sigma(W_{2}\\cdot x_{1}+b_{2});\\qquad ..\\qquad x_{n}=\\sigma(W_{n}x_{n-1}+b_{n}),$$\n","\n","Here  $W_{k}\\in \\mathbb{R}^{d_{k}\\times d_{k-1}}$ are weight matrices, $b_{k}\\in\n","\\mathbb{R}^{d_{k}}$ are bias vectors, $x_{0}$ is the input vector. Schematically, $k$-th block is given by\n","$$z_{k}=W_{k}x_{k-1}+b_{k}; \\qquad x_{k}=\\sigma(z_{k})$$\n","<center><img src=\"https://i.ibb.co/VCYnD8T/block.png\" alt=\"block\" height=200></center>\n","\n","Consider the **random initialization** of weights:\n","* Weights $(W_k)_{ij}$ are i.i.d. with mean $0$ and variance $\\frac{\\sigma_{w}^{2}}{d_{k-1}}$\n","* Biases $(h_k)_{i}$ are i.i.d. with mean $0$ and variance $\\sigma_{h}^{2}$"]},{"cell_type":"code","metadata":{"id":"kucOCjxjZwoK","colab_type":"code","colab":{}},"source":["np.random.seed(0xBADBEEF)\n","\n","d = 300\n","K = 100\n","\n","std_w = 0.8\n","std_b = 1.\n","\n","Wlist = [np.random.randn(d,d) for k in range(K)]\n","hList = [np.random.randn(d,1) for k in range(K)]\n","\n","actL = ['relu', 'leaky_relu', 'tanh']\n","colors = dict([(actL[n], ['b','r','g'][n]) for n in range(3)])\n","\n","def h(x, activation):\n","    if activation == 'relu':\n","        return np.clip(x, 0,np.inf)\n","    elif activation == 'leaky_relu':\n","        return x.clip(0,np.inf)+0.5*x.clip(-np.inf,0)\n","    elif activation == 'tanh':\n","        return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n","    \n","def propagate(z0, activation, std_w, std_b):    \n","    zList = [z0]\n","    xList = [h(z0, activation)]\n","    for k in range(K):  \n","        np.dot(Wlist[k], xList[-1])\n","        x_old = xList[-1]\n","        z = np.dot(std_w/np.sqrt(d)*Wlist[k], x_old)+std_b*hList[k]\n","        x = h(z, activation)\n","        zList.append(z)\n","        xList.append(x)\n","    return xList, zList"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dvGqgqHHVi9N","colab_type":"text"},"source":["For simplicity, we assume that $z_{0}$ is the input to the network (instead of $x_{0}$), and investigate the propagation of $z_{0},z_{1},\\dots, z_{n}$, which is given by\n","$$z_{1}=W_{1}\\cdot h(z_{0})+b_{0}; \\qquad z_{2}=W_{2}\\cdot h(z_{1})+b_{1};\\qquad \\dots \\qquad z_{n}=W_{n}\\cdot h(z_{n-1})+b_{n}.$$\n","Let us see what happens with two independent random vectors $z, z'$ propagated through the network. Will their values at the last layers will also be independent?\n","we compute the correlation coefficient\n","$$c_{k}=\\frac{\\langle z_{k},z_{k}''\\rangle}{\\|z_{k}\\|\\cdot \\|z_{k}'\\|}$$."]},{"cell_type":"code","metadata":{"id":"ptnTt9ghVf1O","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,6))\n","z01 = np.random.randn(d,1)\n","z02 = np.random.randn(d,1)\n","for activation in actL:\n","    xList1, zList1 = propagate(z01, activation, std_w, std_b)\n","    xList2, zList2 = propagate(z02, activation, std_w, std_b)\n","    cList = [np.sum(zList1[k]*zList2[k])/np.sqrt(np.sum(zList1[k]**2)*np.sum(zList2[k]**2)) for k in range(K)] # SOLUTION\n","    plt.plot(cList, colors[activation], label=activation)\n","\n","plt.xlabel('layer (k)')\n","plt.ylabel('correlation coefficient')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MQ4a1c0g_drt","colab_type":"text"},"source":["Is this a good result? **Definitely NO!** We see that that two independent vectors become **highly correlated**!\n","Deep Learning Theory says that the correlation depends on the magnitudes of the signal. So, before understanding the correlation phenomena let us analyse **magnitudes**.\n","\n","## Part 1.1. Empirical Analysis of Magnitude\n","\n","To analyze the magnitude, we formally define it:\n","$$\\text{k-th Layer Signal Magnitude}= q_{k}\\stackrel{def}{=} \\frac{\\|z_{k}\\|^{2}}{d_{k}}=\\frac{\\sum_{i=1}^{d_{k}}z_{k,i}^{2}}{d_{k}}$$\n","\n","**Question:** what is the desired behavious of the magnitude? For analysis, it is easier to consider simple cases:\n","\n","* Magnitude is a **FIXED** point: $q_{0}=q_{1}=\\dots=q_{n}$\n","* Magnitude converges to **STABLE** fixed point: $\\lim_{k\\rightarrow \\infty} q_{k}=q^{*}$\n","\n","To begin with, we define the function that propagates the signal through the network.\n","\n","Let us see, how the magnitude of the signal evolves through the layers for given"]},{"cell_type":"code","metadata":{"id":"i0HkCLCLxiMG","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,6))\n","z0 = np.random.randn(d,1)\n","for activation in actL:\n","    xList, zList = propagate(z0, activation, std_w, std_b)\n","    qList = [np.sum(z*z)/d for z in zList]\n","    plt.plot(qList, colors[activation], label=activation)\n","\n","plt.xlabel('layer (k)')\n","plt.ylabel('q')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zQmg9ZXlBuoS","colab_type":"text"},"source":["\n","\n","We see that the signal's magnitude become more-or-less stable. Let us try to understand whether it is a coincidence.\n","\n","## Part 1.2. Theoretical Magnitude Analysis\n","Assume that the layer width $d_{1},\\dots,d_{n}\\gg 1$. By the **Law of Large numbers** magnitude $q_k$ is approximately constant, i.e.\n","$$q_k=\\frac{\\sum_{i=1}^{d_{k}}z_{k,i}^{2}}{d_{k}} ≈ \\mathbb{E}z_{k,i}$$.\n","\n","**Proposition (Poole et al., [arXiv:1606.05340](https://arxiv.org/abs/1606.05340))**\n","\n","The evolution of magnitude $q_k$ is given by\n","$$q_{k}=\\nu(q_{k-1}|\\sigma_{w},\\sigma_{b})=\\sigma_{w}^{2}\\cdot \\mathbb{E}_{s\\sim \\mathcal{N}(0, 1)} \\big[h^{2}(\\sqrt{q_{k-1}}s)\\big]+\\sigma_{b}^{2}.$$\n","\n","The proof is based on Central Limit Theorem & Law of Large numbers.\n","\n","It is hard to compute the exact value for an arbitrary activation function $h$, but empirically it can be estimated by Monte Carlo sampling of $s$. Your job is to implement the Monte-Carlo estimate of function $\\nu$."]},{"cell_type":"code","metadata":{"id":"ncdMLe-pxk8X","colab_type":"code","colab":{}},"source":["def nu(q, activation, std_w, std_b):\n","    N = 10000\n","    s = np.random.randn(N)\n","    expectation = # YOUR SOLUTION HERE\n","    q_new = std_w**2 * expectation +std_b**2\n","    return q_new"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N7H-4sUdCdvk","colab_type":"text"},"source":["Now we plot the function $\\nu(q)$ and for different activation function compute its fixed points $q^{*}$ (such that $\\nu(q^{*})=q^{*}$).\n","."]},{"cell_type":"code","metadata":{"id":"xeoetIHcxmug","colab_type":"code","colab":{}},"source":["q = np.linspace(0,3)\n","q_fixedD = {}\n","\n","plt.figure(figsize=(8,6))\n","for activation in actL:\n","    print('====', activation)\n","    q_new = nu(q, activation, std_w, std_b)\n","    plt.plot(q, q_new, colors[activation], label=activation, )\n","    q_fixed = 1\n","    for k in range(100):\n","        q_fixed = nu(q_fixed, activation, std_w, std_b)\n","    q_fixedD[activation] = q_fixed[0]\n","    print('Stable fixed point:', q_fixedD[activation])\n","    plt.plot([q_fixed], [q_fixed], colors[activation]+'s')\n","\n","plt.plot(q, q, 'k', label='Id')\n","plt.xlabel('$q$', fontsize=15)\n","plt.ylabel('$\\\\nu(q)$', fontsize=15)\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aXWUogHiCzdD","colab_type":"text"},"source":["We plot the magnitude evolution together with found stable points."]},{"cell_type":"code","metadata":{"id":"NBJxgLOYxp8I","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,6))\n","z0 = np.random.randn(d,1)\n","for activation in actL:\n","    xList, zList = propagate(z0, activation, std_w, std_b)\n","    qList = [np.sum(z*z)/d for z in zList]\n","    plt.plot(qList, colors[activation], label=activation)\n","    plt.plot(q_fixedD[activation]*np.ones(len(qList)), colors[activation]+':', label=activation+': fixed point')\n","\n","plt.xlabel('layer (k)', fontsize=15)\n","plt.ylabel('$q$', fontsize=15)\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YOSPR1hsC4oq","colab_type":"text"},"source":["As we see, practical derivations confirm theoretical findings.\n","\n","**Question:** Is the current chosen variance $\\sigma_{w}^{2}, \n","\\sigma_{b}^{2}$ good?"]},{"cell_type":"markdown","metadata":{"id":"2UcF4oZtT4ts","colab_type":"text"},"source":["**Question:** Why is the result should be considered as bad?\n","\n","## Part 3. Theoretical Correlation Analysis\n","\n","We analyze the relations between signal evolution in network for two different vectors. Let $z_{0,1}$ and $z_{0,2}$ be two input vectors. Define the **correlation** by\n","$$q_{k,ab}=\\frac{1}{d_{k}}\\langle z_{k,a},z_{k, b}\\rangle$$\n","for $a,b\\in \\{0, 1\\}$.\n","\n","**Question:** How does $q_{k,ab}$ evolve?\n","\n","We already now how $q_{k,aa}=q_{k}$ evolve! The evolution of $q_{k,01}$ may not be that interesting, if we do not take into account the value of the norms of the corresponding vectors $z_{k, 0}$ and $z_{k, 1}$. Thus, we correlation coefficient:\n","$$c_{k,12}=\\frac{q_{k,12}}{\\sqrt{q_{k,1}q_{k,2}}}$$\n","Implement the function to compute the correlation coefficient.\n","\n","Similar to magnitude analysis, it is possible to provide exact analytical form of correlation evolution (see Poole et al., [arXiv:1606.05340](https://arxiv.org/abs/1606.05340)).\n","\n","$$q_{k,12}=\\mathcal{Q}(q_{k-1,12}, q_{k-1,11}, q_{k-1,22})=[\\text{Some Heavy formula}]$$\n","\n","We consider only the cases, which are the most interesting, i.e. when both $q_{k,11}$ and $q_{k,22}$ are the stable points of the corresponding evolution function $\\nu$.\n","$$\\nu(q^{*})=q{*}=q_{k,11}=q_{k,22}$$\n","\n","Thus, the correlation $c_{k,12}$ (and the covariation $q_{k,12}$) can be expressed as the function of $c_{k-1, 12}$. We denote this function by\n","$$c_{k,12}=\\mathcal{C}_{q^{*}}(c_{k-1,12}).$$\n","It is quive obvious that $c^{*}=1$ is a fixed point of this map\n","\n","**Question:** Is $c^{*}$ stable or not stable?\n","\n","If $c^{*}=1$ is stable, then **we are in trouble**. Think WHY? SO we want this point to be unstable. The stability is determined by the derivative in $c^{*}=1$, which is given by:\n","$$\\chi_{1}=\\frac{\\partial c_{k,12}}{\\partial c_{k-1,12}}|_{c=1}=\\sigma_{w}^{2}\\int\\big(h'(\\sqrt{q^{*}}s)\\big)^{2}\\mathcal{D}s$$\n","\n","* Stable ($|\\chi_{1}| < 1$):\n"," * different input vectors converge\n"," * initial details in the input get lost\n"," * deep network has low expressiveness\n","* Unstable ($|\\chi_{1}| > 1$):\n"," * close input vectors tend to decorrelate\n"," * small changes in the input lead to major deviations\n"," * deep network has high expressiveness"]},{"cell_type":"code","metadata":{"id":"UUayF5dVxwRU","colab_type":"code","colab":{}},"source":["def chi1(std_w, q_fixed):\n","    N = 10000\n","    s = np.random.randn(N)\n","    u = np.dot(np.sqrt(q_fixed).reshape(-1,1), s.reshape(1,-1))\n","    eps = 1e-10\n","    h_deriv = (h(u+eps, activation)-h(u-eps, activation))/(2*eps)\n","    integral = np.mean(h_deriv**2)\n","    return std_w**2*integral  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u-gEQxEnVlij","colab_type":"text"},"source":["We compute the derivatives for different activation functions."]},{"cell_type":"code","metadata":{"id":"ZLuZJi-5xykZ","colab_type":"code","colab":{}},"source":["for activation in actL:\n","    print('====', activation)\n","    print('Chi1:', chi1(std_w, q_fixedD[activation]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vvi4MPZBV0MB","colab_type":"text"},"source":["Now we change the net weight initialisation variance ($\\sigma_{w}$ and $\\sigma_{b}$) and again compute the stable fixed points."]},{"cell_type":"code","metadata":{"id":"6OEvNwtVx0lB","colab_type":"code","colab":{}},"source":["std_w = 1.24\n","std_b = 0.1\n","\n","q = np.linspace(0,0.5)\n","q_fixedD = {}\n","\n","plt.figure(figsize=(8,6))\n","for activation in actL:\n","    print('====', activation)\n","    q_new = nu(q, activation, std_w, std_b)\n","    plt.plot(q, q_new, colors[activation], label=activation, )\n","    q_fixed = 1\n","    for k in range(1000):\n","        q_fixed = nu(q_fixed, activation, std_w, std_b)\n","    q_fixedD[activation] = q_fixed[0]\n","    print('Stable fixed point:', q_fixedD[activation])\n","    plt.plot([q_fixed], [q_fixed], colors[activation]+'s')\n","\n","plt.plot(q, q, 'k', label='Id')\n","plt.xlabel('$q$', fontsize=15)\n","plt.ylabel('$\\\\nu(q)$', fontsize=15)\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"csBrx7gSx4Wp","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,6))\n","z0 = np.random.randn(d,1)\n","for activation in actL:\n","    xList, zList = propagate(z0, activation, std_w, std_b)\n","    qList = [np.sum(z*z)/d for z in zList]\n","    plt.plot(qList, colors[activation], label=activation)\n","    plt.plot(q_fixedD[activation]*np.ones(len(qList)), colors[activation]+':', label=activation+': fixed point')\n","\n","plt.xlabel('layer (k)', fontsize=15)\n","plt.ylabel('$q$', fontsize=15)\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YtNUuGYhWc3e","colab_type":"text"},"source":["We again compute the derivative of the correlation mapping at the point $c^{*}=1$."]},{"cell_type":"code","metadata":{"id":"aa25OXgfznna","colab_type":"code","colab":{}},"source":["for activation in actL:\n","    print('====', activation)\n","    print('Chi1:', chi1(std_w, q_fixedD[activation]))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wcv6jFMPWm9h","colab_type":"text"},"source":["It seems that only for $tanh$ the fixed point $c^{*}=1$ is not stable."]},{"cell_type":"code","metadata":{"id":"qCmYQOY2zpuN","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,6))\n","z01 = np.random.randn(d,1)\n","z02 = z01+0.7*np.random.randn(d,1)\n","for activation in actL:\n","    xList1, zList1 = propagate(z01, activation, std_w, std_b)\n","    xList2, zList2 = propagate(z02, activation, std_w, std_b)\n","    qList = [np.sum(z*z) for z in zList]\n","    cList = [np.sum(zList1[n]*zList2[n])/np.sqrt(np.sum(zList1[n]**2)*np.sum(zList2[n]**2)) for n in range(K)]\n","    plt.plot(cList, colors[activation], label=activation)\n","\n","plt.xlabel('layer (k)')\n","plt.ylabel('correlation coefficient')\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T9VJy_AbXPF8","colab_type":"text"},"source":["## Part 3. Homework\n","* Prove that $tanh$ correlation mapping $C$ has stable point $c^{*}\\neq 1$.\n","* Find the explicit form of the correlation evolution map e $\\mathcal{C}$ for the ReLU nonlinearity."]},{"cell_type":"code","metadata":{"id":"CPpaOTbYXdvV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}